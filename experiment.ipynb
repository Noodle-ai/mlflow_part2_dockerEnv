{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Notebook Examples\n",
    "* MLflow Tracking\n",
    "* MLflow Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MLflow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Tracking API\n",
    "The MLflow tracking API lets you log metrics and artifacts (files) from your data science code and see a history of your runs.\n",
    "\n",
    "The code below logs a run with one parameter (param1), one metric (foo) with three values (1,2,3), and an artifact (a text file containing \"Hello world!\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the mlflow experiment so that we don't have conflicts with absolute paths in the mlruns meta.yaml\n",
    "import mlflow\n",
    "mlflow.set_experiment('notebook')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "# Log a parameter (key-value pair)\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "# Log a metric; metrics can be updated throughout the run\n",
    "mlflow.log_metric(\"foo\", 1)\n",
    "mlflow.log_metric(\"foo\", 2)\n",
    "mlflow.log_metric(\"foo\", 3)\n",
    "# Log an artifact (output file)\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"Hello world!\")\n",
    "mlflow.log_artifact(\"output.txt\")\n",
    "\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Tracking UI\n",
    "By default, wherever you run your program, the tracking API writes data into a local ./mlruns directory. You can then run MLflow's Tracking UI:\n",
    "\n",
    "* type in the terminal\n",
    "    * mlflow ui\n",
    "* view the tracking UI by clicking the http link\n",
    "    * http://localhost:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"screenshots/mlflow_ui.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=screenshots/saved_parms_metrics_txts.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=screenshots/params_graph.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Incorporating MLflow Tracking and MLflow Models \n",
    "\n",
    "In this example MLflow Tracking is used to keep track of different hyperparameters, performance metrics, and artifacts of a linear regression model. MLflow Models is used to store the pickled trained model instance, a file describing the environment the model instance was created in, and a descriptor file that lists several \"flavors\" the model can be used in. MLflow Projects is used to package the training code. And lastly MLflow Models is used to deploy the model to a simple HTTP server.\n",
    "\n",
    "This tutorial uses a dataset to predict the quality of wine based on quantitative features like the wine's \"fixed acidity\", \"pH\", \"residual sugar\", and so on. The dataset is from UCI's machine learning repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "First, train a linear regression model that takes two hyperparameters: alpha and l1_ratio.\n",
    "\n",
    "This example uses the familiar pandas, numpy, and sklearn APIs to create a simple machine learning model. The MLflow tracking APIs log information about each training run like hyperparameters (alpha and l1_ratio) used to train the model, and metrics (root mean square error, mean absolute error, and r2) used to evaluate the model. The example also serializes the model in a format that MLflow knows how to deploy.\n",
    "\n",
    "Each time you run the example, MLflow logs information about your experiment runs in the directory mlruns.\n",
    "\n",
    "You can run the example through the .py script using the following command.\n",
    "* ```python train.py <alpha> <l1_ratio>```\n",
    "\n",
    "Or you can also use the notebook code below that does the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality Sample\n",
    "\n",
    "def train(in_alpha, in_l1_ratio):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "\n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file from the URL\n",
    "    csv_url =\\\n",
    "        'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "    data = pd.read_csv(csv_url, sep=';')\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "\n",
    "    # Set default values if no alpha is provided\n",
    "    if float(in_alpha) is None:\n",
    "        alpha = 0.5\n",
    "    else:\n",
    "        alpha = float(in_alpha)\n",
    "\n",
    "    # Set default values if no l1_ratio is provided\n",
    "    if float(in_l1_ratio) is None:\n",
    "        l1_ratio = 0.5\n",
    "    else:\n",
    "        l1_ratio = float(in_l1_ratio)\n",
    "\n",
    "    # Useful for multiple runs   \n",
    "    with mlflow.start_run():\n",
    "        # Execute ElasticNet\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Elasticnet model (alpha=0.250000, l1_ratio=0.250000):\n  RMSE: 0.7380489682487518\n  MAE: 0.5690312554727687\n  R2: 0.2282012262646781\nElasticnet model (alpha=0.250000, l1_ratio=0.500000):\n  RMSE: 0.748930783857188\n  MAE: 0.5806946169417598\n  R2: 0.20527460024945354\nElasticnet model (alpha=0.250000, l1_ratio=0.750000):\n  RMSE: 0.7662476663327954\n  MAE: 0.5985976516559472\n  R2: 0.1680982095420568\nElasticnet model (alpha=0.500000, l1_ratio=0.250000):\n  RMSE: 0.7596554775612442\n  MAE: 0.5913132541174235\n  R2: 0.18235068599935977\nElasticnet model (alpha=0.500000, l1_ratio=0.500000):\n  RMSE: 0.7931640229276851\n  MAE: 0.6271946374319586\n  R2: 0.10862644997792614\nElasticnet model (alpha=0.500000, l1_ratio=0.750000):\n  RMSE: 0.8318658159940802\n  MAE: 0.6651040854928951\n  R2: 0.019516509058132292\nElasticnet model (alpha=0.750000, l1_ratio=0.250000):\n  RMSE: 0.7837307525653582\n  MAE: 0.6165474987409884\n  R2: 0.1297029612600864\nElasticnet model (alpha=0.750000, l1_ratio=0.500000):\n  RMSE: 0.8318702776765884\n  MAE: 0.6651291355677875\n  R2: 0.019505991453757976\nElasticnet model (alpha=0.750000, l1_ratio=0.750000):\n  RMSE: 0.8331799787336064\n  MAE: 0.669234506901795\n  R2: 0.016416170929074214\n"
    }
   ],
   "source": [
    "# Run the above training code with different hyperparameters (9 runs)\n",
    "alphas = [0.25, 0.5, 0.75]\n",
    "l1_ratios = [0.25, 0.5, 0.75]\n",
    "for i in alphas:\n",
    "    for j in l1_ratios:\n",
    "        train(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Models\n",
    "Next, use the MLflow UI to compare the models that you have produced. In the same current working directory as the one that contains the mlruns run:\n",
    "\n",
    "* type the following command into the terminal in the working directory that contains the mlruns file\n",
    "    * mlflow ui\n",
    "* view the tracking UI by clicking the http link returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"screenshots/tutorial_1_runs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the search feature to quickly filter out many models. For example, the query (metrics.rmse < 0.8) returns all the models with root mean square error less than 0.8. For more complex manipulations, you can download this table as a CSV and use your favorite data munging software to analyze it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"screenshots/tutorial_1_runs_filtered.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Model from Tracking\n",
    "* ```mlflow.<model_flavor>.load_model(modelpath)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './mlruns/1/<run_id>/artifacts/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RMSE: 0.7380489682487518\n  MAE: 0.5690312554727687\n  R2: 0.2282012262646781\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "# Read the wine-quality csv file from the URL\n",
    "csv_url =\\\n",
    "    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "try:\n",
    "    data = pd.read_csv(csv_url, sep=';')\n",
    "except Exception as e:\n",
    "    logger.exception(\n",
    "        \"Unable to download training & test CSV, check your internet connection. Error: %s\", e)\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "\n",
    "# Loading the model\n",
    "loaded_model = mlflow.sklearn.load_model(model_path)\n",
    "\n",
    "# Evaluate Metrics\n",
    "predicted_qualities = loaded_model.predict(test_x)\n",
    "(rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "# Print out metrics\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging Training Code in a Conda Environment with MLflow Projects\n",
    "\n",
    "Now that you have your training code, you can package it so that other data scientists can easily reuse the model, or so that you can run the training remotely. \n",
    "\n",
    "You do this by using MLflow Projects to specify the dependencies and entry points to your code. The MLproject file specifies that the project has the dependencies located in a docker image called mlflow_image and has one entry point that takes two parameters: alpha and l1_ratio. \n",
    "\n",
    "Note: In order for the above logic to be ran as a MLflow Project we have converted the train() function above into a python script named train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=screenshots/mlproject.png width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this project use mlflow run on the folder containing the MLproject file.\n",
    "* ```mlflow run . -P alpha=1.0 -P l1_ratio=1.0 --experiment-name script```\n",
    "\n",
    "After running this command, MLflow runs your training code in a new container with the dependencies specified in mlflow_image.\n",
    "\n",
    "If a repository has an MLproject file you can also run a project directly from GitHub. This tutorial lives in the https://github.com/Noodle-ai/mlflow_part2_dockerEnv repository which you can run with \n",
    "* ```mlflow run https://github.com/Noodle-ai/mlflow_part2_dockerEnv -P alpha=1.0 -P l1_ratio=0.8 --experiment-name script```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving the Model (Local REST API Server)\n",
    "\n",
    "Now that you have packaged your model using the MLproject convention and have identified the best model, it is time to deploy the model using MLflow Models. An MLflow Model is a standard format for packaging machine learning models that can be used in a variety of downstream tools - for example, real-time serving through a REST API or batch inference on Apache Spark. \n",
    "\n",
    "In the example training code, after training the linear regression model, a function in MLflow saved the model as an artifact within the run. \n",
    "\n",
    "* mlflow.sklearn.log_model(lr, \"model\")\n",
    "\n",
    "To view this artifact, you can use the UI again. When you click a date in the list of experiment runs you'll see this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=screenshots/model_artifacts.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the bottom, you can see that the call to mlflow.sklearn.log_model produced three files in ./mlruns/0/<run_id>/artifacts/model. The first file, MLmodel, is a metadata file that tells MLflow how to load the model. The second file is a conda.yaml that contains the model dependencies from the conda environment. The third file, model.pkl, is a serialized version of the linear regression model that you trained. \n",
    "\n",
    "In this example, you can use this MLmodel format with MLflow to deploy a local REST server that can serve predictions. \n",
    "\n",
    "To deploy the server, run the following command.\n",
    "* ```mlflow models serve -m ./mlruns/1/<run_id>/artifacts/model -p 1234```\n",
    "\n",
    "Note:\n",
    "The version of Python used to create the model must be the same as the one running mlflow models serve. If this is not the case, you may see the error. \n",
    "* UnicodeDecodeError: 'ascii' codec can't decode byte 0x9f in position 1: ordinal not in range(128) or raise ValueError, \"unsupported pickle protocol: %d\"\n",
    "\n",
    "Once you have deployed the server, you can pass it some sample data and see the predictions. The following example uses curl to send a JSON-serialized pandas DataFrame with the split orientation to the model server. For more information about the input data formats accepted by the model server, see the MLflow deployment tools documentation.\n",
    "* ```curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://127.0.0.1:1234/invocations```\n",
    "\n",
    "The server should respond with output similar to: \n",
    "```[3.7783608837127516]```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving the Model (Serving the Model as a Docker Image)\n",
    "\n",
    "Note: This command is experimental (may be changed or removed in a future release without warning) and does not guarantee that the arguments nor format of the Docker container will remain the same.\n",
    "\n",
    "Here we build a Docker image whose default entry point serves the specified MLflow model at port 8080 within the container.\n",
    "\n",
    "The command below builds a docker image named \"serve_model\" that serves the model inÂ \"./mlruns/1/<run_id>/artifacts/model\".\n",
    "\n",
    "* ```mlflow models build-docker -m \"./mlruns/1/<run_id>/artifacts/model\" -n \"serve_model\"```\n",
    "\n",
    "We can then serve the model, exposing it at port 5001 on the host with the following command.\n",
    "\n",
    "* ```docker run -p 5001:8080 \"serve_model\"```\n",
    "\n",
    "Once you have created a container that serves the model with the above command, you can pass it some sample data and see the predictions. Similar to above, the following example uses curl to send a JSON-serialized pandas DataFrame with the split orientation to the model server.\n",
    "\n",
    "* ```curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://127.0.0.1:5001/invocations```\n",
    "\n",
    "Again, the server should respond with an output similar to: ```[3.7783608837127516]```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597301228303",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}